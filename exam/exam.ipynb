{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6795c899",
   "metadata": {},
   "source": [
    "Exam text [here](https://gdv.github.io/foundationsCS/students/progetti/2025-project)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d730ee56",
   "metadata": {},
   "source": [
    "# 2025-26 Project\n",
    "\n",
    "You have to work on the [Trending YouTube](https://drive.google.com/file/d/1VuI1NnPzYlhHIMBy-2nBegFoQTATbf8K/view) dataset.\n",
    "\n",
    "## Notes\n",
    "\n",
    "1. It is mandatory to use GitHub for developing the project.\n",
    "2. The project must be a jupyter notebook.\n",
    "3. There is no restriction on the libraries that can be used, nor on the Python version.\n",
    "4. All questions on the project __must__ be asked in the Discussion forum on the course website.\n",
    "5. At most 3 students can be in each group. You must create the groups by yourself. You can use the Discussion forum to create the groups.\n",
    "6. You do not have to send me the project before the discussion.\n",
    "7. You do not have to prepare any slides for the discussion.\n",
    "8. You can use AI tools, but you have to describe in the notebook how you have used such tools and you have to show that you have fully understood everything that you have in your project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c0c520",
   "metadata": {},
   "source": [
    "### 1. Create a single dataframe with the concatenation of all input csv files, adding a column called ```country```\n",
    "### 2. Extract all videos that have no tag.\n",
    "### 3. For each channel, determine the total number of views\n",
    "### 4. Save all rows with disabled comments and disabled ratings, or that have ```video_error_or_removed``` in a new dataframe called ```excluded```, and remove those rows from the original dataframe.\n",
    "### 5. Add a ```like_ratio``` column storing the ratio between the number of likes and of dislikes\n",
    "### 6. Cluster the publish time into 10-minute intervals (e.g. from 02:20 to 02:30)\n",
    "### 7. For each interval, determine the number of videos, average number of likes and of dislikes.\n",
    "### 8. For each tag, determine the number of videos\n",
    "###### Notice that ```tags``` contains a string with several tags.\n",
    "### 9. Find the tags with the largest number of videos\n",
    "### 10. For each (```tags```, ```country```) pair, compute average ratio likes/dislikes\n",
    "### 11. For each (```trending_date```, ```country```) pair, the video with the largest number of views\n",
    "### 12. Divide ```trending_date``` into three columns: ```year```, ```month```, ```day```\n",
    "### 13. For each (```month```, ```country```) pair, the video with the largest number of views\n",
    "### 14. Read all json files with the video categories\n",
    "### 15. For each country, determine how many videos have a category that is not assignable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "6e77372c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "a88c8d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_path = '/Users/marcomanduca/Desktop/data_science/foundation_computer_science/exam/trendingYT'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbdc7fc",
   "metadata": {},
   "source": [
    "### 1. Create a single dataframe with the concatenation of all input csv files, adding a column called ```country```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "3d41f189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: IN_category_id.json\n",
      "Skipping file: IN_category_id.json\n",
      "Processing file: USvideos.csv.zst\n",
      "File: USvideos.csv.zst - Rows: 40949 - Columns: 17\n",
      "Processing file: FRvideos.csv.zst\n",
      "File: FRvideos.csv.zst - Rows: 81673 - Columns: 17\n",
      "Processing file: MXvideos.csv.zst\n",
      "File: MXvideos.csv.zst - Rows: 122124 - Columns: 17\n",
      "Processing file: RU_category_id.json\n",
      "Skipping file: RU_category_id.json\n",
      "Processing file: JP_category_id.json\n",
      "Skipping file: JP_category_id.json\n",
      "Processing file: FR_category_id.json\n",
      "Skipping file: FR_category_id.json\n",
      "Processing file: INvideos.csv.zst\n",
      "File: INvideos.csv.zst - Rows: 159476 - Columns: 17\n",
      "Processing file: GB_category_id.json\n",
      "Skipping file: GB_category_id.json\n",
      "Processing file: KRvideos.csv.zst\n",
      "File: KRvideos.csv.zst - Rows: 194043 - Columns: 17\n",
      "Processing file: KR_category_id.json\n",
      "Skipping file: KR_category_id.json\n",
      "Processing file: JPvideos.csv.zst\n",
      "File: JPvideos.csv.zst - Rows: 214566 - Columns: 17\n",
      "Processing file: DEvideos.csv.zst\n",
      "File: DEvideos.csv.zst - Rows: 255406 - Columns: 17\n",
      "Processing file: MX_category_id.json\n",
      "Skipping file: MX_category_id.json\n",
      "Processing file: CAvideos.csv.zst\n",
      "File: CAvideos.csv.zst - Rows: 296287 - Columns: 17\n",
      "Processing file: CA_category_id.json\n",
      "Skipping file: CA_category_id.json\n",
      "Processing file: US_category_id.json\n",
      "Skipping file: US_category_id.json\n",
      "Processing file: RUvideos.csv.zst\n",
      "File: RUvideos.csv.zst - Rows: 337026 - Columns: 17\n",
      "Processing file: DE_category_id.json\n",
      "Skipping file: DE_category_id.json\n",
      "Processing file: GBvideos.csv.zst\n",
      "File: GBvideos.csv.zst - Rows: 375942 - Columns: 17\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "for el in os.listdir(in_path):\n",
    "    print(f'Processing file: {el}')\n",
    "    in_file = os.path.join(in_path, el)\n",
    "    if el.endswith('.csv.zst') and el not in ['MXvideos.csv.zst', 'KRvideos.csv.zst', 'JPvideos.csv.zst', 'RUvideos.csv.zst']:\n",
    "        #continue\n",
    "        temp_df = pd.read_csv(\n",
    "            in_file,\n",
    "            compression='zstd',\n",
    "            encoding='utf-8', # invalide bytes in MXvideos, KRvideos, JPvideos, RUvideos files\n",
    "            encoding_errors='ignore',\n",
    "            na_values=['[none]'], # exclude '[none]' as NaN in 'tags' column\n",
    "            parse_dates = ['publish_time']\n",
    "        )\n",
    "    elif el in ['MXvideos.csv.zst', 'KRvideos.csv.zst', 'JPvideos.csv.zst', 'RUvideos.csv.zst']:\n",
    "        temp_df = pd.read_csv(\n",
    "            in_file,\n",
    "            compression='zstd',\n",
    "            encoding_errors='ignore',\n",
    "            na_values=['[none]'], # exclude '[none]' as NaN in 'tags' column\n",
    "            parse_dates = ['publish_time']\n",
    "        )\n",
    "    else:\n",
    "        print(f'Skipping file: {el}')\n",
    "        continue\n",
    "    temp_df['country'] = el[:2]\n",
    "    df = pd.concat([df, temp_df], ignore_index=True, axis = 0)\n",
    "    print(f'File: {el} - Rows: {df.shape[0]} - Columns: {df.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "1637bb89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>trending_date</th>\n",
       "      <th>title</th>\n",
       "      <th>channel_title</th>\n",
       "      <th>category_id</th>\n",
       "      <th>publish_time</th>\n",
       "      <th>tags</th>\n",
       "      <th>views</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>thumbnail_link</th>\n",
       "      <th>comments_disabled</th>\n",
       "      <th>ratings_disabled</th>\n",
       "      <th>video_error_or_removed</th>\n",
       "      <th>description</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56985</th>\n",
       "      <td>-iBnb_KyUZ8</td>\n",
       "      <td>18.04.02</td>\n",
       "      <td>Friends Trip 4 Episode 25</td>\n",
       "      <td>channel TV</td>\n",
       "      <td>24</td>\n",
       "      <td>2018-02-03 08:45:09+00:00</td>\n",
       "      <td>Friends Trip 4 Episode 25</td>\n",
       "      <td>21215</td>\n",
       "      <td>85</td>\n",
       "      <td>23</td>\n",
       "      <td>16</td>\n",
       "      <td>https://i.ytimg.com/vi/-iBnb_KyUZ8/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Friends Trip 4 Episode 25 \\nhttp://www.dailymo...</td>\n",
       "      <td>FR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181957</th>\n",
       "      <td>gL9-CWUpBTY</td>\n",
       "      <td>18.29.03</td>\n",
       "      <td>2018ÎÖÑ 3Ïõî 28Ïùº ÏÉùÎ∞©ÏÜ° PenN Îâ¥Ïä§</td>\n",
       "      <td>Ï†ïÍ∑úÏû¨TV</td>\n",
       "      <td>25</td>\n",
       "      <td>2018-03-28 11:01:31+00:00</td>\n",
       "      <td>Ï†ïÍ∑úÏû¨|\"Ï†ïÍ∑úÏû¨Ìã∞ÎπÑ\"|\"Ï†ïÍ∑úÏû¨TV\"|\"ÌéúÏï§Îâ¥Ïä§\"|\"ÌéúÏï§ÎßàÏù¥ÌÅ¨\"|\"ÍπÄÏ†ïÏùÄ\"|\"Îã®Í≥ÑÏ†Å ...</td>\n",
       "      <td>92566</td>\n",
       "      <td>4910</td>\n",
       "      <td>147</td>\n",
       "      <td>362</td>\n",
       "      <td>https://i.ytimg.com/vi/gL9-CWUpBTY/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>* Ïò§ÎäòÏùò PenN Îâ¥Ïä§ ÌÉÄÏù¥ÌãÄ *\\n0. Î¨∏Ïû¨Ïù∏Í≥º ÍπÄÏ†ïÏùÄÏùò Ï∞®Ïù¥, Î¨∏Ï†ïÏù∏ÏùÄ Ïûò Î¥§...</td>\n",
       "      <td>KR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2207</th>\n",
       "      <td>nkXGohB02V0</td>\n",
       "      <td>17.25.11</td>\n",
       "      <td>Fast Food (A Thanksgiving Special) - Simon's C...</td>\n",
       "      <td>Simon's Cat</td>\n",
       "      <td>15</td>\n",
       "      <td>2017-11-23 13:04:34+00:00</td>\n",
       "      <td>cartoon|\"simons cat\"|\"simon's cat\"|\"simonscat\"...</td>\n",
       "      <td>659371</td>\n",
       "      <td>27060</td>\n",
       "      <td>579</td>\n",
       "      <td>1373</td>\n",
       "      <td>https://i.ytimg.com/vi/nkXGohB02V0/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>'Two hungry cats join forces to gobble down a ...</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87917</th>\n",
       "      <td>7d9pVZLhhi4</td>\n",
       "      <td>17.15.12</td>\n",
       "      <td>El Flechado de Aura casi golpea a Brian por cu...</td>\n",
       "      <td>LosVaM's</td>\n",
       "      <td>24</td>\n",
       "      <td>2017-12-15 00:04:04+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36533</td>\n",
       "      <td>118</td>\n",
       "      <td>20</td>\n",
       "      <td>18</td>\n",
       "      <td>https://i.ytimg.com/vi/7d9pVZLhhi4/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244853</th>\n",
       "      <td>CSsnZJ1En7U</td>\n",
       "      <td>18.22.04</td>\n",
       "      <td>Priyamanaval Episode 995, 21/04/18</td>\n",
       "      <td>VikatanTV</td>\n",
       "      <td>24</td>\n",
       "      <td>2018-04-21 17:00:00+00:00</td>\n",
       "      <td>Priyamanaval 21.04.2018|\"priyamanaval 995\"|\"pr...</td>\n",
       "      <td>492465</td>\n",
       "      <td>2729</td>\n",
       "      <td>881</td>\n",
       "      <td>395</td>\n",
       "      <td>https://i.ytimg.com/vi/CSsnZJ1En7U/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Priyamanaval Episode 995\\nSubscribe: https://g...</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           video_id trending_date  \\\n",
       "56985   -iBnb_KyUZ8      18.04.02   \n",
       "181957  gL9-CWUpBTY      18.29.03   \n",
       "2207    nkXGohB02V0      17.25.11   \n",
       "87917   7d9pVZLhhi4      17.15.12   \n",
       "244853  CSsnZJ1En7U      18.22.04   \n",
       "\n",
       "                                                    title channel_title  \\\n",
       "56985                           Friends Trip 4 Episode 25    channel TV   \n",
       "181957                   2018ÎÖÑ 3Ïõî 28Ïùº ÏÉùÎ∞©ÏÜ° PenN Îâ¥Ïä§      Ï†ïÍ∑úÏû¨TV   \n",
       "2207    Fast Food (A Thanksgiving Special) - Simon's C...   Simon's Cat   \n",
       "87917   El Flechado de Aura casi golpea a Brian por cu...      LosVaM's   \n",
       "244853                 Priyamanaval Episode 995, 21/04/18     VikatanTV   \n",
       "\n",
       "        category_id              publish_time  \\\n",
       "56985            24 2018-02-03 08:45:09+00:00   \n",
       "181957           25 2018-03-28 11:01:31+00:00   \n",
       "2207             15 2017-11-23 13:04:34+00:00   \n",
       "87917            24 2017-12-15 00:04:04+00:00   \n",
       "244853           24 2018-04-21 17:00:00+00:00   \n",
       "\n",
       "                                                                               tags  \\\n",
       "56985                           Friends Trip 4 Episode 25                             \n",
       "181957  Ï†ïÍ∑úÏû¨|\"Ï†ïÍ∑úÏû¨Ìã∞ÎπÑ\"|\"Ï†ïÍ∑úÏû¨TV\"|\"ÌéúÏï§Îâ¥Ïä§\"|\"ÌéúÏï§ÎßàÏù¥ÌÅ¨\"|\"ÍπÄÏ†ïÏùÄ\"|\"Îã®Í≥ÑÏ†Å ...   \n",
       "2207    cartoon|\"simons cat\"|\"simon's cat\"|\"simonscat\"...                             \n",
       "87917                                                 NaN                             \n",
       "244853  Priyamanaval 21.04.2018|\"priyamanaval 995\"|\"pr...                             \n",
       "\n",
       "         views  likes  dislikes  comment_count  \\\n",
       "56985    21215     85        23             16   \n",
       "181957   92566   4910       147            362   \n",
       "2207    659371  27060       579           1373   \n",
       "87917    36533    118        20             18   \n",
       "244853  492465   2729       881            395   \n",
       "\n",
       "                                        thumbnail_link  comments_disabled  \\\n",
       "56985   https://i.ytimg.com/vi/-iBnb_KyUZ8/default.jpg              False   \n",
       "181957  https://i.ytimg.com/vi/gL9-CWUpBTY/default.jpg              False   \n",
       "2207    https://i.ytimg.com/vi/nkXGohB02V0/default.jpg              False   \n",
       "87917   https://i.ytimg.com/vi/7d9pVZLhhi4/default.jpg              False   \n",
       "244853  https://i.ytimg.com/vi/CSsnZJ1En7U/default.jpg              False   \n",
       "\n",
       "        ratings_disabled  video_error_or_removed  \\\n",
       "56985              False                   False   \n",
       "181957             False                   False   \n",
       "2207               False                   False   \n",
       "87917              False                   False   \n",
       "244853             False                   False   \n",
       "\n",
       "                                                                      description  \\\n",
       "56985   Friends Trip 4 Episode 25 \\nhttp://www.dailymo...                           \n",
       "181957  * Ïò§ÎäòÏùò PenN Îâ¥Ïä§ ÌÉÄÏù¥ÌãÄ *\\n0. Î¨∏Ïû¨Ïù∏Í≥º ÍπÄÏ†ïÏùÄÏùò Ï∞®Ïù¥, Î¨∏Ï†ïÏù∏ÏùÄ Ïûò Î¥§...   \n",
       "2207    'Two hungry cats join forces to gobble down a ...                           \n",
       "87917                                                 NaN                           \n",
       "244853  Priyamanaval Episode 995\\nSubscribe: https://g...                           \n",
       "\n",
       "       country  \n",
       "56985       FR  \n",
       "181957      KR  \n",
       "2207        US  \n",
       "87917       MX  \n",
       "244853      DE  "
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c26d929",
   "metadata": {},
   "source": [
    "### 2. Extract all videos that have no tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "edc3e258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of videos without tags: 37,698 (10.03% of the total)\n"
     ]
    }
   ],
   "source": [
    "video_no_tags = df[df['tags'].isnull()]\n",
    "print(f'Number of videos without tags: {format(video_no_tags.shape[0], \",d\")} ({format(video_no_tags.shape[0]/df.shape[0]*100, \".2f\")}% of the total)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8557562",
   "metadata": {},
   "source": [
    "### 3. For each channel, determine the total number of views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "732aef45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>views</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>channel_title</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ChildishGambinoVEVO</th>\n",
       "      <td>11016766510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Marvel Entertainment</th>\n",
       "      <td>10430605449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NickyJamTV</th>\n",
       "      <td>9479859505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ozuna</th>\n",
       "      <td>8623329509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ibighit</th>\n",
       "      <td>8205572221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NavylittleMonster</th>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Videostendencias</th>\n",
       "      <td>302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No Comment TV</th>\n",
       "      <td>284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sport Life</th>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alexander Redking</th>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37824 rows √ó 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            views\n",
       "channel_title                    \n",
       "ChildishGambinoVEVO   11016766510\n",
       "Marvel Entertainment  10430605449\n",
       "NickyJamTV             9479859505\n",
       "Ozuna                  8623329509\n",
       "ibighit                8205572221\n",
       "...                           ...\n",
       "NavylittleMonster             365\n",
       "Videostendencias              302\n",
       "No Comment TV                 284\n",
       "Sport Life                    163\n",
       "Alexander Redking             153\n",
       "\n",
       "[37824 rows x 1 columns]"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(by=['channel_title']).agg(\n",
    "    {'views' : 'sum'}\n",
    ").sort_values(by='views', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b122bc",
   "metadata": {},
   "source": [
    "### 4. Save all rows with disabled comments and disabled ratings, or that have ```video_error_or_removed``` in a new dataframe called ```excluded```, and remove those rows from the original dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "6b7e1cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total videos before exclusion: 375,942\n",
      "Total excluded videos: 2,620\n",
      "Total videos after exclusion: 373,322\n"
     ]
    }
   ],
   "source": [
    "print(f'Total videos before exclusion: {format(df.shape[0], \",d\")}')\n",
    "excluded = df[\n",
    "    (df['comments_disabled'] == True) & (df['ratings_disabled'] == True) |\n",
    "    (df['video_error_or_removed'] == True)\n",
    "]\n",
    "\n",
    "print(f'Total excluded videos: {format(excluded.shape[0], \",d\")}')\n",
    "\n",
    "df = df.drop(excluded.index)\n",
    "print(f'Total videos after exclusion: {format(df.shape[0], \",d\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa12499e",
   "metadata": {},
   "source": [
    "### 5. Add a ```like_ratio``` column storing the ratio between the number of likes and of dislikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "22650640",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['like_ratio'] = df['likes'] / df['dislikes']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86027cd",
   "metadata": {},
   "source": [
    "### 6. Cluster the publish time into 10-minute intervals (e.g. from 02:20 to 02:30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "a07402f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cluster'] = (df['publish_time'].dt.hour * 60 + df['publish_time'].dt.minute) // 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc00fdf",
   "metadata": {},
   "source": [
    "### 7. For each interval, determine the number of videos, average number of likes and of dislikes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "e736adde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_videos</th>\n",
       "      <th>avg_likes</th>\n",
       "      <th>avg_dislikes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2897</td>\n",
       "      <td>61288.115637</td>\n",
       "      <td>3808.149465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1509</td>\n",
       "      <td>22748.138502</td>\n",
       "      <td>1449.836315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1241</td>\n",
       "      <td>21378.280419</td>\n",
       "      <td>1072.344883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1614</td>\n",
       "      <td>36853.560719</td>\n",
       "      <td>955.890954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1269</td>\n",
       "      <td>42198.623325</td>\n",
       "      <td>1909.301812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>1554</td>\n",
       "      <td>22783.840412</td>\n",
       "      <td>1110.168597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>1438</td>\n",
       "      <td>30696.510431</td>\n",
       "      <td>1177.020862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>1666</td>\n",
       "      <td>18159.173469</td>\n",
       "      <td>874.184874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>1466</td>\n",
       "      <td>45736.581855</td>\n",
       "      <td>9341.549795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>1269</td>\n",
       "      <td>10853.743893</td>\n",
       "      <td>505.701340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         total_videos     avg_likes  avg_dislikes\n",
       "cluster                                          \n",
       "0                2897  61288.115637   3808.149465\n",
       "1                1509  22748.138502   1449.836315\n",
       "2                1241  21378.280419   1072.344883\n",
       "3                1614  36853.560719    955.890954\n",
       "4                1269  42198.623325   1909.301812\n",
       "...               ...           ...           ...\n",
       "139              1554  22783.840412   1110.168597\n",
       "140              1438  30696.510431   1177.020862\n",
       "141              1666  18159.173469    874.184874\n",
       "142              1466  45736.581855   9341.549795\n",
       "143              1269  10853.743893    505.701340\n",
       "\n",
       "[144 rows x 3 columns]"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(by=['cluster']).agg(\n",
    "    {'video_id' : 'count', 'likes' : 'mean', 'dislikes' : 'mean'}\n",
    ").rename(\n",
    "    columns={'video_id' : 'total_videos', 'likes' : 'avg_likes', 'dislikes' : 'avg_dislikes'}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e91fe52",
   "metadata": {},
   "source": [
    "### 8. For each tag, determine the number of videos\n",
    "### 9. Find the tags with the largest number of videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d754cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_id = df.set_index('video_id')\n",
    "# | (pipe) to split the tags, explode to expand the dataframe into multiple rows with the same video_id\n",
    "tags = df_with_id['tags'].str.split('|').explode()\n",
    "tags = tags.reset_index().rename(columns = {\n",
    "    'index' : 'video_id',\n",
    "    'tags' : 'tag'\n",
    "})\n",
    "\n",
    "#tag like \"funny\" and funny (or \"comedy\" and comedy) are the same. remove the double quotes\n",
    "tags['tag'] = tags['tag'].str.replace('\"', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "9103d3bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>video_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>355882</th>\n",
       "      <td>funny</td>\n",
       "      <td>15039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296168</th>\n",
       "      <td>comedy</td>\n",
       "      <td>12351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12818</th>\n",
       "      <td>2018</td>\n",
       "      <td>11371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466731</th>\n",
       "      <td>news</td>\n",
       "      <td>6363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458682</th>\n",
       "      <td>music</td>\n",
       "      <td>5909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576534</th>\n",
       "      <td>tuzhat jeev rangala 23 march 2018 full episode</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178662</th>\n",
       "      <td>Rerfuerzos america 2018</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576532</th>\n",
       "      <td>tuzhat jeev rangala 21apr 2018episode</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576531</th>\n",
       "      <td>tuzhat jeev rangala 21 march 2018 full episode</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>849300</th>\n",
       "      <td>ü§ù ZARBEX zahlt Schutzgeld!!!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>849301 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tag  video_count\n",
       "355882                                           funny        15039\n",
       "296168                                          comedy        12351\n",
       "12818                                             2018        11371\n",
       "466731                                            news         6363\n",
       "458682                                           music         5909\n",
       "...                                                ...          ...\n",
       "576534  tuzhat jeev rangala 23 march 2018 full episode            1\n",
       "178662                         Rerfuerzos america 2018            1\n",
       "576532           tuzhat jeev rangala 21apr 2018episode            1\n",
       "576531  tuzhat jeev rangala 21 march 2018 full episode            1\n",
       "849300                   ü§ù ZARBEX zahlt Schutzgeld!!!            1\n",
       "\n",
       "[849301 rows x 2 columns]"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags.groupby(\n",
    "    by=['tag'],\n",
    "    as_index = False\n",
    ").size().rename(\n",
    "    columns = {'size' : 'video_count'}\n",
    ").sort_values(\n",
    "    by=['video_count'],\n",
    "    ascending = False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0619e8",
   "metadata": {},
   "source": [
    "### 10. For each (```tags```, ```country```) pair, compute average ratio likes/dislikes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
